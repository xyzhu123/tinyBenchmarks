{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aeb0a714-9d15-41bc-ac06-ce5a1e448b1d",
   "metadata": {},
   "source": [
    "# Training Item Response Theory (IRT) models\n",
    "\n",
    "In this notebook, we show how to train your own Item Response Theory (IRT) models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7008d96d-1ee5-44cf-91cb-293fb3e048bf",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85d9b93-5059-416c-8a53-e3b4cc24a904",
   "metadata": {},
   "source": [
    "Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7892164d-f5bb-4cef-9f4f-685a9af85679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from irt import *\n",
    "from utils import *\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebb8ce2-1851-4131-8d35-36214be71085",
   "metadata": {},
   "source": [
    "The leaderboard dataset we will use is composed by six scenarios (sub-datasets):\n",
    "1. TruthfulQA\n",
    "1. GSM8K\n",
    "1. Winogrande\n",
    "1. ARC\n",
    "1. HellaSwag\n",
    "1. MMLU\n",
    "\n",
    "MMLU is further divided into sub-scenarios (e.g., abstract algebra, anatomy, etc). Let's check scenarios and sub-scenarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26499fc1-2bda-44b2-9131-e78d16f7f77d",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "scenarios\n",
    "\n",
    "scenarios = {'wmdp_cyber':['wmdp_cyber'],\n",
    "             'wmdp_bio':['wmdp_bio'],}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34e5620-bd45-4985-b390-a154843b4d6c",
   "metadata": {},
   "source": [
    "Loading leaderboard data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca68f5c-49de-4f75-92e5-de639059cec1",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "with open('wmdp_data.pkl', 'rb') as handle:\n",
    "    data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f14f180-d322-4cd5-8d0c-4ae4fef04127",
   "metadata": {},
   "source": [
    "In this dataset, we have data from 395 models. Let's see the names of some of them below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d8135b-e9ec-468a-85a7-3cd3fc3d31fe",
   "metadata": {},
   "source": [
    "Below, we will process the data so all correctness scores (for all scenarios) are stored in $Y$. The dictionaries `scenarios_position` and `subscenarios_position` give the position of scenarios/subscenarios correctness scores in $Y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee09c25b-2dc4-4403-a972-9fb05cfe917b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 3260)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "scenarios_position, subscenarios_position = prepare_data(scenarios, data)\n",
    "Y = create_responses(scenarios, data)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e002485a-1e82-409b-aaf2-ddb6a82bc315",
   "metadata": {},
   "source": [
    "For example, below you can see the scores for MMLU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dd9649-ba75-49c0-92fe-b00d2afc252e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 1., ..., 0., 1., 0.],\n",
       "        [1., 1., 1., ..., 1., 1., 0.],\n",
       "        [1., 0., 1., ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [0., 1., 1., ..., 0., 1., 0.],\n",
       "        [0., 1., 1., ..., 0., 1., 0.],\n",
       "        [1., 0., 1., ..., 0., 1., 1.]]),\n",
       " (64, 1987))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "Y[:,scenarios_position['wmdp_cyber']], Y[:,scenarios_position['wmdp_cyber']].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d062bc-1efe-4527-b40c-96fc295e05fe",
   "metadata": {},
   "source": [
    "For scenarios that have multiple subscenarios, it is usually the case that we want to give equal importance to individual subscenarios when computing the aggregated performance in that scenario. This is equivalent to using a weighted average when computing the aggregated performance. We will create balance_weights, a vector of weights to help us compute those weighted averages. These weights will be different than one only for MMLU, which is the only scenario with multiple subscenarios.\n",
    "\n",
    "We will use this when choosing the IRT dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c2e717-c575-4b0c-8067-15574c3dde3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "balance_weights = np.ones(Y.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d106b620-7fe0-49bb-a8ac-3a946c15f751",
   "metadata": {},
   "source": [
    "## Training IRT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844c4412-ae69-4184-b106-191a1c151736",
   "metadata": {},
   "source": [
    "Let's split the data in train and test (recent models are placed in the test set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9874c5-7cb5-425b-8c41-9a87d7615ba2",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "Y_test = Y[:16]\n",
    "Y_train = Y[16:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5facf520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 3260) (16, 3260)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e856d5-3778-417f-b4e9-77cfc9f6e6a1",
   "metadata": {},
   "source": [
    "To train the IRT model, we first need to binarize the values in $Y$ because correctness is not binary for TruthfulQA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739556a1-fd5c-4edb-8fd2-2e0914377eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 2148.52it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 3312.67it/s]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "Y_bin_train = np.zeros(Y_train.shape)\n",
    "Y_bin_test = np.zeros(Y_test.shape)\n",
    "\n",
    "cs = np.linspace(0.01,.99,100)  # Threshold values to consider\n",
    "for scenario in scenarios.keys():\n",
    "    ind = scenarios_position[scenario]\n",
    "    # Find the best threshold value that minimizes the difference between averages\n",
    "    c = cs[np.argmin([np.mean((np.abs((Y_train[:,ind]>c).mean(axis=1)-Y_train[:,ind].mean(axis=1)))) for c in tqdm(cs)])]\n",
    "    # Apply the threshold to train and test responses\n",
    "    Y_bin_train[:,ind] = (Y_train[:,ind]>c).astype(int)\n",
    "    Y_bin_test[:,ind] = (Y_test[:,ind]>c).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964dbee2-3607-4f6a-b287-29f12b5e20d5",
   "metadata": {},
   "source": [
    "Choosing the dimension for the IRT model based on a simple validation heuristic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9999beb9-9796-45ea-993b-cd293d343002",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:45:13] config: model_type='multidim_2pl' epochs=2000              cli.py:109\n",
      "           priors='hierarchical' initializers=[] dims=5 lr=0.1                  \n",
      "           lr_decay=0.9999 dropout=0.5 hidden=100 vocab_size=None               \n",
      "           log_every=200 seed=42 deterministic=True                             \n",
      "           data_path: data/irt_val_dataset.jsonlines                  cli.py:111\n",
      "           output directory: data/irt_val_model/                      cli.py:112\n",
      "[23:45:13] amortized: False                                       dataset.py:112\n",
      "[23:45:13] Vocab size: None                                       training.py:90\n",
      "           Training Model...                                          cli.py:116\n",
      "           args: {'device': 'cpu', 'num_items': 3260,            training.py:134\n",
      "           'num_subjects': 38}                                                  \n",
      "           Parsed Model Args: {'device': 'cpu', 'num_items':     training.py:147\n",
      "           3260, 'num_subjects': 38, 'priors': 'hierarchical',                  \n",
      "           'dims': 5, 'dropout': 0.5, 'hidden': 100,                            \n",
      "           'vocab_size': None}                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/data/amos_zhu/miniconda3/envs/tinybenchmarks/bin/py-irt\", line 6, in <module>\n",
      "    sys.exit(app())\n",
      "             ^^^^^\n",
      "  File \"/data/amos_zhu/miniconda3/envs/tinybenchmarks/lib/python3.11/site-packages/typer/main.py\", line 214, in __call__\n",
      "    return get_command(self)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/data/amos_zhu/miniconda3/envs/tinybenchmarks/lib/python3.11/site-packages/click/core.py\", line 829, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/data/amos_zhu/miniconda3/envs/tinybenchmarks/lib/python3.11/site-packages/click/core.py\", line 782, in main\n",
      "    rv = self.invoke(ctx)\n",
      "         ^^^^^^^^^^^^^^^^\n",
      "  File \"/data/amos_zhu/miniconda3/envs/tinybenchmarks/lib/python3.11/site-packages/click/core.py\", line 1259, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/data/amos_zhu/miniconda3/envs/tinybenchmarks/lib/python3.11/site-packages/click/core.py\", line 1066, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/data/amos_zhu/miniconda3/envs/tinybenchmarks/lib/python3.11/site-packages/click/core.py\", line 610, in invoke\n",
      "    return callback(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/data/amos_zhu/miniconda3/envs/tinybenchmarks/lib/python3.11/site-packages/typer/main.py\", line 497, in wrapper\n",
      "    return callback(**use_params)  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/data/amos_zhu/tinyBenchmarks/tutorials/py-irt/py_irt/cli.py\", line 117, in train\n",
      "    trainer.train(device=device)\n",
      "  File \"/data/amos_zhu/tinyBenchmarks/tutorials/py-irt/py_irt/training.py\", line 153, in train\n",
      "    scheduler = pyro.optim.ExponentialLR(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: module 'pyro.optim' has no attribute 'ExponentialLR'\n",
      "  0%|          | 0/2 [00:09<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3260,) (1,28659) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 35\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m scenario \u001b[38;5;129;01min\u001b[39;00m scenarios\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m     34\u001b[0m     ind \u001b[38;5;241m=\u001b[39m [u \u001b[38;5;28;01mfor\u001b[39;00m u \u001b[38;5;129;01min\u001b[39;00m unseen_items \u001b[38;5;28;01mif\u001b[39;00m u \u001b[38;5;129;01min\u001b[39;00m scenarios_position[scenario]]\n\u001b[0;32m---> 35\u001b[0m     errors2[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean(\u001b[43m[\u001b[49m\u001b[38;5;28;43mabs\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbalance_weights\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mitem_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthetas\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mind\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mY_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mval_ind\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43mind\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_ind\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m))\n\u001b[1;32m     36\u001b[0m errors\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean(errors2[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n",
      "Cell \u001b[0;32mIn[12], line 35\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m scenario \u001b[38;5;129;01min\u001b[39;00m scenarios\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m     34\u001b[0m     ind \u001b[38;5;241m=\u001b[39m [u \u001b[38;5;28;01mfor\u001b[39;00m u \u001b[38;5;129;01min\u001b[39;00m unseen_items \u001b[38;5;28;01mif\u001b[39;00m u \u001b[38;5;129;01min\u001b[39;00m scenarios_position[scenario]]\n\u001b[0;32m---> 35\u001b[0m     errors2[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean([\u001b[38;5;28mabs\u001b[39m((\u001b[43mbalance_weights\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mitem_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthetas\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[43m)\u001b[49m)[\u001b[38;5;241m0\u001b[39m,ind]\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m-\u001b[39mY_train[val_ind][j,ind]\u001b[38;5;241m.\u001b[39mmean())\u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(val_ind))]))\n\u001b[1;32m     36\u001b[0m errors\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean(errors2[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3260,) (1,28659) "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "Ds = [5,10] # Dimensions to try\n",
    "device = 'cpu' # Either 'cuda' or 'cpu' \n",
    "epochs = 2000  # Number of epochs for IRT model training (py-irt default is 2000)\n",
    "lr = .1  # Learning rate for IRT model training (py-irt default is .1)\n",
    "\n",
    "val_ind = list(range(0,Y_bin_train.shape[0],5)) # Validation indices\n",
    "train_ind = [i for i in range(Y_bin_train.shape[0]) if i not in val_ind]\n",
    "\n",
    "# Saving the training dataset in the needed format\n",
    "create_irt_dataset(Y_bin_train[train_ind], 'data/irt_val_dataset.jsonlines')\n",
    "\n",
    "# Trying different Ds\n",
    "errors = []  \n",
    "errors2 = []\n",
    "\n",
    "for D in tqdm(Ds):\n",
    "    dataset_name = 'data/irt_val_dataset.jsonlines'\n",
    "    model_name = 'data/irt_val_model/'\n",
    "    \n",
    "    # Load trained IRT model parameters\n",
    "    train_irt_model(dataset_name, model_name, D, lr, epochs, device)\n",
    "    A, B, Theta = load_irt_parameters(model_name)\n",
    "    \n",
    "    # Determine seen and unseen items for validation\n",
    "    seen_items = list(range(0, Y_bin_train.shape[1], 2))\n",
    "    unseen_items = list(range(1, Y_bin_train.shape[1], 2))\n",
    "\n",
    "    # Estimate ability parameters for the validation set\n",
    "    thetas = [estimate_ability_parameters(Y_bin_train[val_ind][j][seen_items], A[:, :, seen_items], B[:, :, seen_items]) for j in range(len(val_ind))]\n",
    "\n",
    "    # Compute validation errors for each scenario and update the errors list (in the end, we give the same weight for all scenarios)\n",
    "    errors2.append([])\n",
    "    for scenario in scenarios.keys():\n",
    "        ind = [u for u in unseen_items if u in scenarios_position[scenario]]\n",
    "        errors2[-1].append(np.mean([abs((balance_weights*item_curve(thetas[j], A, B))[0,ind].mean()-Y_train[val_ind][j,ind].mean())for j in range(len(val_ind))]))\n",
    "    errors.append(np.mean(errors2[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbdc2b3-fb4e-4075-b1df-a747ce7d68e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmin of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ind_D \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m D \u001b[38;5;241m=\u001b[39m Ds[ind_D]\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36margmin\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/tinybenchmarks/lib/python3.11/site-packages/numpy/core/fromnumeric.py:1338\u001b[0m, in \u001b[0;36margmin\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   1251\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;124;03mReturns the indices of the minimum values along an axis.\u001b[39;00m\n\u001b[1;32m   1253\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1335\u001b[0m \u001b[38;5;124;03m(2, 1, 4)\u001b[39;00m\n\u001b[1;32m   1336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1337\u001b[0m kwds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m-> 1338\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43margmin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tinybenchmarks/lib/python3.11/site-packages/numpy/core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;31mValueError\u001b[0m: attempt to get argmin of an empty sequence"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "ind_D = np.argmin(np.array(errors))\n",
    "D = Ds[ind_D]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8680d6e6-1ec2-4a24-a898-f29bd5ec109e",
   "metadata": {},
   "source": [
    "Saving the training dataset in the needed format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a80e3b-8e0c-402f-8263-7e178b976bc8",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mJupyter notebook failed to launch. \n",
      "\u001b[1;31mKernel not initialized in Session. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "create_irt_dataset(Y_bin_train, 'data/irt_dataset.jsonlines')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2aa8114-a6b3-493c-8220-9f8976131a53",
   "metadata": {},
   "source": [
    "To train the IRT model, we use an adapted version of `py-irt` code (please check README in the tutorials directory for mode details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dcda49-4f05-4350-9dcf-d09addc8f983",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mJupyter notebook failed to launch. \n",
      "\u001b[1;31mKernel not initialized in Session. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "train_irt_model(dataset_name='data/irt_dataset.jsonlines', \n",
    "                model_name='data/irt_model', \n",
    "                D=D, lr=lr, epochs=epochs, device=device)               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0f46f1",
   "metadata": {},
   "source": [
    "## Get the values for $\\lambda$ which will be used to get the gp-IRT estimates (in conjunction with anchor methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e186b7ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mJupyter notebook failed to launch. \n",
      "\u001b[1;31mKernel not initialized in Session. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def get_lambda(b, v):\n",
    "    return (b**2)/(v+(b**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c5c76c",
   "metadata": {},
   "source": [
    "The variable `number_item` gives the number of data points we will sample per scenario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9962b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mJupyter notebook failed to launch. \n",
      "\u001b[1;31mKernel not initialized in Session. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "number_item = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2fd007",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mJupyter notebook failed to launch. \n",
      "\u001b[1;31mKernel not initialized in Session. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "lambds = {} \n",
    "\n",
    "for i,scenario in enumerate(scenarios.keys()):\n",
    "    v = np.var(Y_train[:,scenarios_position[scenario]], axis=1).mean()\n",
    "    b = np.mean(errors2[ind_D][i]) \n",
    "    lambds[scenario] = get_lambda(b, v/(4*number_item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b270a850",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mJupyter notebook failed to launch. \n",
      "\u001b[1;31mKernel not initialized in Session. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "with open('data/lambds.pickle', 'wb') as handle:\n",
    "    pickle.dump(lambds, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
